<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Quantum GANs | TomMago</title>
<meta name="keywords" content="GSoC">
<meta name="description" content="This year I&rsquo;m participating in the Google Summer of Code again. Just like last year I&rsquo;m working with the ML4SCI organization. In this years project I am working on Quantum Generative Adversarial Networks.
GANs
Generative Adversarial Networks (GANs) are a class of unsupervised machine learning models proposed in 




(No matching key was found for `Goodfellow2014` in the references. Please make sure to provide an available ID in your `bib.json` file.)
. GANs aim to train a generator $G(z,\Theta_g)$ with a latent space $z$ and parameters $\Theta_g$ to replicate a reference probability distribution when sampling from the latent space $z$.">
<meta name="author" content="Tom Magorsch">
<link rel="canonical" href="https://tommago.com/posts/qgan/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.2215a03600b60f1af3cfb8faa798da315a17443436f4572cbbbec618c5735bd8.css" integrity="sha256-IhWgNgC2Dxrzz7j6p5jaMVoXRDQ29Fcsu77GGMVzW9g=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://tommago.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://tommago.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://tommago.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://tommago.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://tommago.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://tommago.com/posts/qgan/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css" integrity="sha384-Xi8rHCmBmhbuyyhbI88391ZKP2dmfnOl4rT9ZfRI7mLTdk1wblIUnrIq35nqwEvC" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js" integrity="sha384-X/XCfMm41VSsqRNQgDerQczD69XqmjOOOwYQvr/uuC+j4OPoNhVgjdGFwhvN02Ja" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
onload="renderMathInElement(document.body,
        {
              delimiters: [
                  {left: '$$', right: '$$', display: true},
                  {left: '$', right: '$', display: false},
              ],
              throwOnError : false
          });"></script>



<link rel="stylesheet" type="text/css" href="/hugo-cite.css" />

      <script async src="https://www.googletagmanager.com/gtag/js?id=G-9MSJDZKGWH"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-9MSJDZKGWH');
        }
      </script><meta property="og:title" content="Quantum GANs" />
<meta property="og:description" content="This year I&rsquo;m participating in the Google Summer of Code again. Just like last year I&rsquo;m working with the ML4SCI organization. In this years project I am working on Quantum Generative Adversarial Networks.
GANs
Generative Adversarial Networks (GANs) are a class of unsupervised machine learning models proposed in 




(No matching key was found for `Goodfellow2014` in the references. Please make sure to provide an available ID in your `bib.json` file.)
. GANs aim to train a generator $G(z,\Theta_g)$ with a latent space $z$ and parameters $\Theta_g$ to replicate a reference probability distribution when sampling from the latent space $z$." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://tommago.com/posts/qgan/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-29T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2023-07-29T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Quantum GANs"/>
<meta name="twitter:description" content="This year I&rsquo;m participating in the Google Summer of Code again. Just like last year I&rsquo;m working with the ML4SCI organization. In this years project I am working on Quantum Generative Adversarial Networks.
GANs
Generative Adversarial Networks (GANs) are a class of unsupervised machine learning models proposed in 




(No matching key was found for `Goodfellow2014` in the references. Please make sure to provide an available ID in your `bib.json` file.)
. GANs aim to train a generator $G(z,\Theta_g)$ with a latent space $z$ and parameters $\Theta_g$ to replicate a reference probability distribution when sampling from the latent space $z$."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://tommago.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Quantum GANs",
      "item": "https://tommago.com/posts/qgan/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Quantum GANs",
  "name": "Quantum GANs",
  "description": "This year I\u0026rsquo;m participating in the Google Summer of Code again. Just like last year I\u0026rsquo;m working with the ML4SCI organization. In this years project I am working on Quantum Generative Adversarial Networks.\nGANs Generative Adversarial Networks (GANs) are a class of unsupervised machine learning models proposed in (No matching key was found for `Goodfellow2014` in the references. Please make sure to provide an available ID in your `bib.json` file.) . GANs aim to train a generator $G(z,\\Theta_g)$ with a latent space $z$ and parameters $\\Theta_g$ to replicate a reference probability distribution when sampling from the latent space $z$.\n",
  "keywords": [
    "GSoC"
  ],
  "articleBody": "This year I’m participating in the Google Summer of Code again. Just like last year I’m working with the ML4SCI organization. In this years project I am working on Quantum Generative Adversarial Networks.\nGANs Generative Adversarial Networks (GANs) are a class of unsupervised machine learning models proposed in (No matching key was found for `Goodfellow2014` in the references. Please make sure to provide an available ID in your `bib.json` file.) . GANs aim to train a generator $G(z,\\Theta_g)$ with a latent space $z$ and parameters $\\Theta_g$ to replicate a reference probability distribution when sampling from the latent space $z$.\nA GAN consists of two networks, the generator $G$ and a discriminator $D$. The networks are trained by playing a zero sum game, where the generator tries to generate samples which are as realistic as possible, while the discriminator tries to classify real data samples and tag samples generated by the generator as fake.\nA schematic sketch of a GAN is shown below.\nBoth the generator and the discriminator are trained independently by the classification results of the discriminator. If the generator $G(z,\\Theta_g)$ is neural network which maps from the latent space to the space $\\Omega$, then the discriminator $D:\\Omega\\to[0,1]$ classifies the data with $D=1$ corresponding to the discriminator tagging a sample as real and $D=0$ as fake. The objective function $\\mathcal{L}(\\Theta_g, \\Theta_d)$ can then be written as $$\\mathcal{L}(\\Theta_g, \\Theta_d) = E_{x\\sim\\mu_{train}}[\\ln D(x)]+E_{z\\sim\\mu_z}[\\ln(1-D(G(z)))],$$ and the training as a min-max optimization of the form $$\\min_{\\Theta_g}\\max_{\\Theta_d}\\mathcal{L}(\\Theta_g,\\Theta_d).$$ The expecation values $E$ run over the training data and the latent space distribution respectively.\nThis min-max loss can be recast into a different form with two distinct loss functions, one for the discriminator $\\mathcal{L}_D$ and one for the generator $\\mathcal{L}_G$ $$\\mathcal{L}_D(\\Theta_g,\\Theta_d) = E_{z\\sim\\mu_z}[\\ln D(G(z))]+E_{x\\sim x_{train}}[\\ln(1-D(x))],$$ $$\\mathcal{L}_G(\\Theta_g,\\Theta_d) = -E_{z\\sim\\mu_z}[\\ln D(1-G(z))].$$ Both of these are minimized, with respect to their parameters, while freezing the parameters of the opponent network. $$\\min_{\\Theta_d} \\mathcal{L}_D(\\Theta_g,\\Theta_d),$$ $$\\min_{\\Theta_g} \\mathcal{L}_G(\\Theta_g,\\Theta_d).$$\nTo check that this make sense, we can think about the terms in the loss function: The discriminator wants to tag the generators samples as fake ($D(G(z))=0$) and data samples as real ($D(x)=1$). Inserting these values in $\\mathcal{L}_D$ would minimize both terms.\nGANs in hep There has been a vast amount of work on generative models applied to high energy physics tasks, e.g. (No matching key was found for `Oliveira2017` in the references. Please make sure to provide an available ID in your `bib.json` file.No matching key was found for `Butter2019` in the references. Please make sure to provide an available ID in your `bib.json` file.No matching key was found for `Hariri2021` in the references. Please make sure to provide an available ID in your `bib.json` file.) . The main incentive is to speed up the simulation of particle physics processes by training a GAN, which then cheaply be sampled from.\nIn the typical analysis pipline of a high energy physics (HEP) experiment, one of the computationally most demanding steps is the generation of expected reference data from our assumed theory (the Standard Model of particle physics). Classical event generator rely on Monte-Carlo techniques to sample from the respective event distributions, which is a very demanding step. A GAN can in principle learn the structure even of complex events once and then generate events more efficiently.\nQGAN Building on the success of classical GANs in generative tasks, similar models have been proposed to perform generative tasks on quantum computers (No matching key was found for `Lloyd2018` in the references. Please make sure to provide an available ID in your `bib.json` file.No matching key was found for `DallaireDemers2018` in the references. Please make sure to provide an available ID in your `bib.json` file.) . There are different motivations for a Quantum Generative Adversarial Network (QGAN), what I find particularly intersting is:\nThe measurement of a quantum system can, under certain assumptions, generate classical data, which can not be generted efficiently by a classical model (based on a classical random number generator) (No matching key was found for `Preskill2018` in the references. Please make sure to provide an available ID in your `bib.json` file.) , which implies a quantum advantage in generative tasks of such distributions. The concept of a QRAM (No matching key was found for `Giovannetti2007` in the references. Please make sure to provide an available ID in your `bib.json` file.) aims to represent a large data vector of size $N$ in $\\log N$ qubits. Together with the ability of quantum computers to perform maniputlations of sparse and low rank $N\\times N$ matrices with a scaling of $\\mathcal{O}(\\text{poly}(\\log N))$ implies that there is a potential advantage in the scaling of sampling in QGANs (No matching key was found for `Lloyd2018` in the references. Please make sure to provide an available ID in your `bib.json` file.) From a practical point of view I think QGANs offer interesing applications for e.g. state preperation, to learn a shallower circuit to load an approximation of a probability distribution, instead of deeper exact circuits. QGAN circuit There are many different proposals for QGANs, with both fully quantum architectures, or hybrid models with a classical discriminator network, see e.g. (No matching key was found for `Romero2019` in the references. Please make sure to provide an available ID in your `bib.json` file.No matching key was found for `Tian2022` in the references. Please make sure to provide an available ID in your `bib.json` file.) for reviews.\nThe simplest version of a fully quantum QGAN can be build with a SWAP test as discriminator.\nIn this case the discriminator does not have parameters and therefore, we do not have an adversarial min-max training. Also, we do not have a latent space $z$ to sample from. Instead we just want to train the generator unitarity $G(\\Theta_g)$ to produce a state which is a superposition of the input states $\\sigma_i$ $$G(\\Theta_g)\\ket{0} = \\sum P_i \\sigma_i.$$\nThe generator parameters can be trained by maximizing the fidelity $F(\\sigma,G(\\Theta))$ of the generator $G(\\Theta)$ and the input data $\\sigma$ $$F(\\sigma,G(\\Theta))=\\left|\\braket{\\sigma|G(\\Theta)}\\right|^2.$$ In practice I use the following loss function for minimization $$\\mathcal{L}(\\Theta_g) = -\\log\\left(G(\\Theta_g)\\epsilon\\right),$$ with some small regularization $\\epsilon$.\nMeasuring the generetor circuit would then correspond to sampling from the data distribution. While I perfom this simple training on a noiseless simulator, (No matching key was found for `Niu2021` in the references. Please make sure to provide an available ID in your `bib.json` file.) shows that adding parameters $\\Theta_d$ to the SWAP test, making the fidelity loss “imperfect”, can make the training more robust to device noise.\nImplementing a simple QGAN (toy data) As a simple toy example I want to train a QGAN to load a gaussian peak. So I start off by generating a toy dataset drawing $N=120$ integers between $0$ and $15$ from a normal distribution with $\\mu=7$ and $\\sigma=1.5$.\nTo load the data, I convert the integers to 4 bit values and encode them in quantum states of a four qubit quantum register. To implement the quantum circuits and the optimization I use the pennylane library. The for the generator circuit, I use a strongly entangled layer. The code for the training circuit is given below.\ndev = qml.device('lightning.qubit', wires=9) def num_circuit(num, wires): # Cast numberst to binary bin_str = format(num, '#06b')[2:] # Apply X to appropiate wires for i, c in enumerate(bin_str): if c == '1': qml.PauliX(wires=i+wires[0]) def generator(params_g, qubits): qml.StronglyEntanglingLayers(weights=params_g, wires=qubits) @qml.qnode(dev) def training_circ(data, params_g): # Real data num_circuit(data, [1,2,3,4]) # Generator circuit generator(params_g, [5,6,7,8]) # SWAP test qml.Hadamard(wires=0) qml.CSWAP(wires=[0,1,5]) qml.CSWAP(wires=[0,2,6]) qml.CSWAP(wires=[0,3,7]) qml.CSWAP(wires=[0,4,8]) qml.Hadamard(wires=0) return qml.expval(qml.PauliZ(0)) To perform the training, I loop over the data samples and optimize the parameters using Adam.\n# The first dimension corresponds to the number of layers in the generator # Since we need some expressiveness a higher number will give better results params_g = np.random.uniform(0,np.pi, size=(18,4,3), requires_grad=True) epochs = 110 batch_size=16 learning_rate=0.01 def iterate_minibatches(data, batch_size): for start_idx in range(0, data.shape[0] - batch_size + 1, batch_size): idxs = slice(start_idx, start_idx + batch_size) yield data[idxs] def cost_batch(paramsg, paramsd, batch, reg=0.000001): loss = 0.0 for i in batch: f = training_circ(i, paramsg) + reg loss += - np.log(f) return loss / len(batch) # Training loop for it in range(epochs): for j,Xbatch in enumerate(iterate_minibatches(data, batch_size=batch_size)): cost_fn = lambda p: cost_batch(p, Xbatch) params_g = optg.step(cost_fn, params_g) print(j, end=\"\\r\") loss = cost_batch(params_g, data) print(f\"Epoch: {it} | Loss: {loss:.3} | \") print(\"____\") Performing the optimization until convergence sets the generator parameters. We can then define a circuit which only contains the generator and sample in the computational basis.\nsample_dev = qml.device('lightning.qubit', wires=4, shots = N) @qml.qnode(sample_dev) def sample_test(): generator(paramsg, [0,1,2,3]) return qml.sample() testresult = [int(''.join(str(i) for i in a), 2) for a in sample_test()] If we convert the computational basis results back to integers we can check how well the generator aprroximates our data distribution.\nOutlook For further work, I’m interested in a couple of things. First I want to see how complex the distributions can be which I can train in this matter. Then I want to implement the same model with a classical discriminator and compare the training with the fully quantum one. Finally, I want to extend the model to a continous value QGAN by using an embedding for the continous input data, and add a latent space $z$ to the generator. In this way it should be possible to sample from a continous distribution, by taking an expectatin value over a number of shots when drawing from the generator.\nReferences Bibliography called, but no references ",
  "wordCount" : "1563",
  "inLanguage": "en",
  "datePublished": "2023-07-29T00:00:00Z",
  "dateModified": "2023-07-29T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Tom Magorsch"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://tommago.com/posts/qgan/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "TomMago",
    "logo": {
      "@type": "ImageObject",
      "url": "https://tommago.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://tommago.com/" accesskey="h" title="TomMago (Alt + H)">TomMago</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://tommago.com/talks/" title="Talks">
                    <span>Talks</span>
                </a>
            </li>
            <li>
                <a href="https://notes.tommago.com" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="https://tommago.com/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://tommago.com/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://tommago.com/">Home</a>&nbsp;»&nbsp;<a href="https://tommago.com/posts/">Posts</a></div>
    <h1 class="post-title">
      Quantum GANs
    </h1>
    <div class="post-meta"><span title='2023-07-29 00:00:00 +0000 UTC'>July 29, 2023</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Tom Magorsch

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#gans" aria-label="GANs">GANs</a></li>
                <li>
                    <a href="#gans-in-hep" aria-label="GANs in hep">GANs in hep</a></li>
                <li>
                    <a href="#qgan" aria-label="QGAN">QGAN</a><ul>
                        
                <li>
                    <a href="#qgan-circuit" aria-label="QGAN circuit">QGAN circuit</a></li>
                <li>
                    <a href="#implementing-a-simple-qgan-toy-data" aria-label="Implementing a simple QGAN (toy data)">Implementing a simple QGAN (toy data)</a></li></ul>
                </li>
                <li>
                    <a href="#outlook" aria-label="Outlook">Outlook</a></li>
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>This year I&rsquo;m participating in the Google Summer of Code again. Just like last year I&rsquo;m working with the <a href="https://ml4sci.org">ML4SCI</a> organization. In this years <a href="https://summerofcode.withgoogle.com/programs/2023/projects/ggoiGDQ5">project</a> I am working on Quantum Generative Adversarial Networks.</p>
<h2 id="gans">GANs<a hidden class="anchor" aria-hidden="true" href="#gans">#</a></h2>
<p>Generative Adversarial Networks (GANs) are a class of unsupervised machine learning models proposed in 




<span class="hugo-cite-intext"
        itemprop="citation">(<span style="background-color: #f00; color: #fff;">No matching key was found for `Goodfellow2014` in the references. Please make sure to provide an available ID in your `bib.json` file.</span>)</span>
. GANs aim to train a generator $G(z,\Theta_g)$ with a latent space $z$ and parameters $\Theta_g$ to replicate a reference probability distribution when sampling from the latent space $z$.</p>
<p>A GAN consists of two networks, the generator $G$ and a discriminator $D$. The networks are trained by playing a zero sum game, where the generator tries to generate samples which are as realistic as possible, while the discriminator tries to classify real data samples and tag samples generated by the generator as fake.</p>
<p>A schematic sketch of a GAN is shown below.</p>
<p><img loading="lazy" src="../gan.png#center" alt="schematic sketch of a GAN"  />
</p>
<p>Both the generator and the discriminator are trained independently by the classification results of the discriminator.
If the generator $G(z,\Theta_g)$ is neural network which maps from the latent space to the space $\Omega$, then the discriminator $D:\Omega\to[0,1]$ classifies the data with $D=1$ corresponding to the discriminator tagging a sample as real and $D=0$ as fake.
The objective function $\mathcal{L}(\Theta_g, \Theta_d)$ can then be written as
$$\mathcal{L}(\Theta_g, \Theta_d) = E_{x\sim\mu_{train}}[\ln D(x)]+E_{z\sim\mu_z}[\ln(1-D(G(z)))],$$
and the training as a min-max optimization of the form
$$\min_{\Theta_g}\max_{\Theta_d}\mathcal{L}(\Theta_g,\Theta_d).$$
The expecation values $E$ run over the training data and the latent space distribution respectively.</p>
<p>This min-max loss can be recast into a different form with two distinct loss functions, one for the discriminator $\mathcal{L}_D$ and one for the generator $\mathcal{L}_G$
$$\mathcal{L}_D(\Theta_g,\Theta_d) = E_{z\sim\mu_z}[\ln D(G(z))]+E_{x\sim x_{train}}[\ln(1-D(x))],$$
$$\mathcal{L}_G(\Theta_g,\Theta_d) = -E_{z\sim\mu_z}[\ln D(1-G(z))].$$
Both of these are minimized, with respect to their parameters, while freezing the parameters of the opponent network.
$$\min_{\Theta_d} \mathcal{L}_D(\Theta_g,\Theta_d),$$
$$\min_{\Theta_g} \mathcal{L}_G(\Theta_g,\Theta_d).$$</p>
<p>To check that this make sense, we can think about the terms in the loss function: The discriminator wants to tag the generators samples as fake ($D(G(z))=0$) and data samples as real ($D(x)=1$). Inserting these values in $\mathcal{L}_D$ would minimize both terms.</p>
<h2 id="gans-in-hep">GANs in hep<a hidden class="anchor" aria-hidden="true" href="#gans-in-hep">#</a></h2>
<p>There has been a vast amount of work on generative models applied to high energy physics tasks, e.g. 




<span class="hugo-cite-intext"
        itemprop="citation">(<span style="background-color: #f00; color: #fff;">No matching key was found for `Oliveira2017` in the references. Please make sure to provide an available ID in your `bib.json` file.</span><span style="background-color: #f00; color: #fff;">No matching key was found for `Butter2019` in the references. Please make sure to provide an available ID in your `bib.json` file.</span><span style="background-color: #f00; color: #fff;">No matching key was found for `Hariri2021` in the references. Please make sure to provide an available ID in your `bib.json` file.</span>)</span>
. The main incentive is to speed up the simulation of particle physics processes by training a GAN, which then cheaply be sampled from.</p>
<p>In the typical analysis pipline of a high energy physics (HEP) experiment, one of the computationally most demanding steps is the generation of expected reference data from our assumed theory (the Standard Model of particle physics). Classical event generator rely on Monte-Carlo techniques to sample from the respective event distributions, which is a very demanding step. A GAN can in principle learn the structure even of complex events once and then generate events more efficiently.</p>
<h2 id="qgan">QGAN<a hidden class="anchor" aria-hidden="true" href="#qgan">#</a></h2>
<p>Building on the success of classical GANs in generative tasks, similar models have been proposed to perform generative tasks on quantum computers 




<span class="hugo-cite-intext"
        itemprop="citation">(<span style="background-color: #f00; color: #fff;">No matching key was found for `Lloyd2018` in the references. Please make sure to provide an available ID in your `bib.json` file.</span><span style="background-color: #f00; color: #fff;">No matching key was found for `DallaireDemers2018` in the references. Please make sure to provide an available ID in your `bib.json` file.</span>)</span>
. There are different motivations for a Quantum Generative Adversarial Network (QGAN), what I find particularly intersting is:</p>
<ol>
<li>The measurement of a quantum system can, under certain assumptions, generate classical data, which can not be generted efficiently by a classical model (based on a classical random number generator) 




<span class="hugo-cite-intext"
        itemprop="citation">(<span style="background-color: #f00; color: #fff;">No matching key was found for `Preskill2018` in the references. Please make sure to provide an available ID in your `bib.json` file.</span>)</span>
, which implies a quantum advantage in generative tasks of such distributions.</li>
<li>The concept of a QRAM 




<span class="hugo-cite-intext"
        itemprop="citation">(<span style="background-color: #f00; color: #fff;">No matching key was found for `Giovannetti2007` in the references. Please make sure to provide an available ID in your `bib.json` file.</span>)</span>
 aims to represent a large data vector of size $N$ in $\log N$ qubits. Together with the ability of quantum computers to perform maniputlations of sparse and low rank $N\times N$ matrices with a scaling of $\mathcal{O}(\text{poly}(\log N))$ implies that there is a potential advantage in the scaling of sampling in QGANs 




<span class="hugo-cite-intext"
        itemprop="citation">(<span style="background-color: #f00; color: #fff;">No matching key was found for `Lloyd2018` in the references. Please make sure to provide an available ID in your `bib.json` file.</span>)</span>
</li>
<li>From a practical point of view I think QGANs offer interesing applications for e.g. state preperation, to learn a shallower circuit to load an approximation of a probability distribution, instead of deeper exact circuits.</li>
</ol>
<h3 id="qgan-circuit">QGAN circuit<a hidden class="anchor" aria-hidden="true" href="#qgan-circuit">#</a></h3>
<p>There are many different proposals for QGANs, with both fully quantum architectures, or hybrid models with a classical discriminator network, see e.g. 




<span class="hugo-cite-intext"
        itemprop="citation">(<span style="background-color: #f00; color: #fff;">No matching key was found for `Romero2019` in the references. Please make sure to provide an available ID in your `bib.json` file.</span><span style="background-color: #f00; color: #fff;">No matching key was found for `Tian2022` in the references. Please make sure to provide an available ID in your `bib.json` file.</span>)</span>
 for reviews.</p>
<p>The simplest version of a fully quantum QGAN can be build with a <a href="https://en.wikipedia.org/wiki/Swap_test">SWAP test</a> as discriminator.</p>
<p><img loading="lazy" src="../qgan_circuit.png#center" alt="schematic sketch of a GAN"  />
</p>
<p>In this case the discriminator does not have parameters and therefore, we do not have an adversarial min-max training. Also, we do not have a latent space $z$ to sample from. Instead we just want to train the generator unitarity $G(\Theta_g)$ to produce a state which is a superposition of the input states $\sigma_i$
$$G(\Theta_g)\ket{0} = \sum P_i \sigma_i.$$</p>
<p>The generator parameters can be trained by maximizing the fidelity $F(\sigma,G(\Theta))$ of the generator $G(\Theta)$ and the input data $\sigma$
$$F(\sigma,G(\Theta))=\left|\braket{\sigma|G(\Theta)}\right|^2.$$
In practice I use the following loss function for minimization
$$\mathcal{L}(\Theta_g) = -\log\left(G(\Theta_g)\epsilon\right),$$
with some small regularization $\epsilon$.</p>
<p>Measuring the generetor circuit would then correspond to sampling from the data distribution. While I perfom this simple training on a noiseless simulator, 




<span class="hugo-cite-intext"
        itemprop="citation">(<span style="background-color: #f00; color: #fff;">No matching key was found for `Niu2021` in the references. Please make sure to provide an available ID in your `bib.json` file.</span>)</span>
 shows that adding parameters $\Theta_d$ to the SWAP test, making the fidelity loss &ldquo;imperfect&rdquo;, can make the training more robust to device noise.</p>
<h3 id="implementing-a-simple-qgan-toy-data">Implementing a simple QGAN (toy data)<a hidden class="anchor" aria-hidden="true" href="#implementing-a-simple-qgan-toy-data">#</a></h3>
<p>As a simple toy example I want to train a QGAN to load a gaussian peak.
So I start off by generating a toy dataset drawing $N=120$ integers between $0$ and $15$ from a normal distribution with $\mu=7$ and $\sigma=1.5$.</p>
<p><img loading="lazy" src="../peak.png#center" alt="schematic sketch of a GAN"  />
</p>
<p>To load the data, I convert the integers to 4 bit values and encode them in quantum states of a four qubit quantum register.
To implement the quantum circuits and the optimization I use the <a href="https://pennylane.ai/">pennylane library</a>.
The for the generator circuit, I use a strongly entangled layer. The code for the training circuit is given below.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">dev</span> <span class="o">=</span> <span class="n">qml</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;lightning.qubit&#39;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">num_circuit</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">wires</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Cast numberst to binary</span>
</span></span><span class="line"><span class="cl">    <span class="n">bin_str</span> <span class="o">=</span> <span class="nb">format</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="s1">&#39;#06b&#39;</span><span class="p">)[</span><span class="mi">2</span><span class="p">:]</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Apply X to appropiate wires</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bin_str</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">c</span> <span class="o">==</span> <span class="s1">&#39;1&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">qml</span><span class="o">.</span><span class="n">PauliX</span><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="n">i</span><span class="o">+</span><span class="n">wires</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">generator</span><span class="p">(</span><span class="n">params_g</span><span class="p">,</span> <span class="n">qubits</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">qml</span><span class="o">.</span><span class="n">StronglyEntanglingLayers</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">params_g</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">qubits</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@qml.qnode</span><span class="p">(</span><span class="n">dev</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">training_circ</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">params_g</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Real data</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_circuit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Generator circuit</span>
</span></span><span class="line"><span class="cl">    <span class="n">generator</span><span class="p">(</span><span class="n">params_g</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># SWAP test</span>
</span></span><span class="line"><span class="cl">    <span class="n">qml</span><span class="o">.</span><span class="n">Hadamard</span><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">qml</span><span class="o">.</span><span class="n">CSWAP</span><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">qml</span><span class="o">.</span><span class="n">CSWAP</span><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">qml</span><span class="o">.</span><span class="n">CSWAP</span><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">7</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">qml</span><span class="o">.</span><span class="n">CSWAP</span><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">8</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">qml</span><span class="o">.</span><span class="n">Hadamard</span><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">qml</span><span class="o">.</span><span class="n">expval</span><span class="p">(</span><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span></span></code></pre></div><p>To perform the training, I loop over the data samples and optimize the parameters using Adam.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># The first dimension corresponds to the number of layers in the generator</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Since we need some expressiveness a higher number will give better results</span>
</span></span><span class="line"><span class="cl"><span class="n">params_g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">epochs</span> <span class="o">=</span> <span class="mi">110</span>
</span></span><span class="line"><span class="cl"><span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span>
</span></span><span class="line"><span class="cl"><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">iterate_minibatches</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">start_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">idxs</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">yield</span> <span class="n">data</span><span class="p">[</span><span class="n">idxs</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">cost_batch</span><span class="p">(</span><span class="n">paramsg</span><span class="p">,</span> <span class="n">paramsd</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mf">0.000001</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.0</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">f</span> <span class="o">=</span> <span class="n">training_circ</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">paramsg</span><span class="p">)</span> <span class="o">+</span> <span class="n">reg</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span> <span class="o">+=</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Training loop</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">j</span><span class="p">,</span><span class="n">Xbatch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">iterate_minibatches</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)):</span> 
</span></span><span class="line"><span class="cl">        <span class="n">cost_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">cost_batch</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">Xbatch</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">params_g</span> <span class="o">=</span> <span class="n">optg</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">cost_fn</span><span class="p">,</span> <span class="n">params_g</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&#34;</span><span class="se">\r</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">loss</span> <span class="o">=</span> <span class="n">cost_batch</span><span class="p">(</span><span class="n">params_g</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Epoch: </span><span class="si">{</span><span class="n">it</span><span class="si">}</span><span class="s2"> | Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.3</span><span class="si">}</span><span class="s2"> | &#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;____&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>Performing the optimization until convergence sets the generator parameters.
We can then define a circuit which only contains the generator and sample in the computational basis.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">sample_dev</span> <span class="o">=</span> <span class="n">qml</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;lightning.qubit&#39;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shots</span> <span class="o">=</span> <span class="n">N</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nd">@qml.qnode</span><span class="p">(</span><span class="n">sample_dev</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">sample_test</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">generator</span><span class="p">(</span><span class="n">paramsg</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">qml</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">testresult</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">a</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">sample_test</span><span class="p">()]</span>
</span></span></code></pre></div><p>If we convert the computational basis results back to integers we can check how well the generator aprroximates our data distribution.</p>
<p><img loading="lazy" src="../peakgan.png#center" alt="schematic sketch of a GAN"  />
</p>
<h2 id="outlook">Outlook<a hidden class="anchor" aria-hidden="true" href="#outlook">#</a></h2>
<p>For further work, I&rsquo;m interested in a couple of things. First I want to see how complex the distributions can be which I can train in this matter. Then I want to implement the same model with a classical discriminator and compare the training with the fully quantum one. Finally, I want to extend the model to a continous value QGAN by using an embedding for the continous input data, and add a latent space $z$ to the generator. In this way it should be possible to sample from a continous distribution, by taking an expectatin value over a number of shots when drawing from the generator.</p>
<h2 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h2>

  

  










Bibliography called, but no references





  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://tommago.com/tags/gsoc/">GSoC</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2026 <a href="https://tommago.com/">TomMago</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
